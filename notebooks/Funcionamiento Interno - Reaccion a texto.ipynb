{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar la reaccion a un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 0: Definimos que es un interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una funcion para extraer las raices de las palabras\n",
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interest:\n",
    "    def __init__(self, keyword, strenght=0.5, polarity=0.5):\n",
    "        # Get synonyms\n",
    "        self._keywords = []\n",
    "        if wn.synsets(keyword):\n",
    "            for word, tag in pos_tag(wn.synsets(keyword)[0].lemma_names()):\n",
    "                if '_' in word:\n",
    "                    continue\n",
    "                    \n",
    "                if tag == 'NNP':\n",
    "                    self._keywords += [word.lower()]\n",
    "                else:\n",
    "                    self._keywords += [lemmatize_stemming(word).lower()]\n",
    "        else:\n",
    "            self._keywords = [lemmatize_stemming(keyword)]\n",
    "            \n",
    "        self._strenght = strenght\n",
    "        self._polarity = polarity\n",
    "    \n",
    "    def get_list(self):\n",
    "        return (self._keywords, self._strenght, self._polarity)\n",
    "\n",
    "    def get_keywords(self):\n",
    "        return self._keywords\n",
    "\n",
    "    def get_polarity(self):\n",
    "        return self._polarity\n",
    "\n",
    "    def get_strenght(self):\n",
    "        return self._strenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Preparamos uno interes y un texto al que relacionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A alguien que no le gustan los gatos\n",
    "interest = Interest(\"cat\", 0.8, 0.1)\n",
    "\n",
    "# Un texto de alguien a quien le gustan los gatos\n",
    "text = \"Cats are just the best! Garfield is getting lasagna tonight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intereses de alguien que ama los perros y odia los gatos\n",
    "interests = [Interest(\"dog\", 0.7, 0.9),\n",
    "             Interest(\"cat\", 0.8, 0.1)\n",
    "            ]\n",
    "\n",
    "# Textos con opiniones variadas sobre perros y gatos\n",
    "texts = [\n",
    "    \"Man, last night a dog bite me, and it sucked, I hate dogs from now on\",\n",
    "    \"Just got a new dog and its name is Kale! We are so excited!!\",\n",
    "    \"Cats are just the best! Garfield is getting lasagna tonight\",\n",
    "    \"Garfield the cat is a fat asshole\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Extraemos las raices de las palabras del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "En el texto: \n",
      "Cats are just the best! Garfield is getting lasagna tonight\n",
      "Existen las siguientes raices utiles:\n",
      "['cat', 'garfield', 'tonight']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos una funcion que nos dice si la palabra es un sustantivo\n",
    "is_useful = lambda pos: pos[:2] in ['NN']#, 'VB']\n",
    "\n",
    "raices=[]\n",
    "\n",
    "# Por cada palabra comprobamos que sea un sustantivo, y si lo es, lo metemos en la lista de raices\n",
    "for token, tag in pos_tag(word_tokenize(text)):\n",
    "    if token[0] == '@':\n",
    "        continue\n",
    "    if not is_useful(tag):\n",
    "        continue\n",
    "\n",
    "    if token and token[0] not in gensim.parsing.preprocessing.STOPWORDS and len(token) >= 3:\n",
    "        res = token if tag == 'NNP' else lemmatize_stemming(token)\n",
    "        raices.append(res.lower())\n",
    "\n",
    "# Ordenamos las raices por numero de ocurrencias\n",
    "raices.sort(key=Counter(raices).get, reverse=True)\n",
    "\n",
    "# Quitamos los duplicados\n",
    "raices = list(dict.fromkeys(raices))\n",
    "\n",
    "print('''\n",
    "En el texto: \n",
    "{}\n",
    "Existen las siguientes raices utiles:\n",
    "{}\n",
    "'''.format(text, raices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que alguna de estas raices tenga que ver con nuestros intereses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay intereses presentes: ['cat']\n"
     ]
    }
   ],
   "source": [
    "matching_keywords = [k for k in interest.get_keywords() if k in raices]\n",
    "\n",
    "if matching_keywords:\n",
    "    print(f\"Hay intereses presentes: {matching_keywords}\")\n",
    "else:\n",
    "    print(\"No hay intereses comunes en el texto, la reaccion es [0.0, 0.0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Calculamos el sentimiento del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El sentimiento del texto es: 1.0\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "text_sentiment = 0.5 + blob.sentiment.polarity/2\n",
    "\n",
    "print(f\"El sentimiento del texto es: {text_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Calculamos como de correcto nos parece el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percibimos que el texto es [0.0] correcto (0 es nada, 1 es completamente)\n"
     ]
    }
   ],
   "source": [
    "our_strenght = interest.get_strenght()\n",
    "our_polarity = interest.get_polarity()\n",
    "\n",
    "# Sentimos que el texto es correcto si se alinea con nuestra percepcion\n",
    "if (our_polarity-0.5 < 0):\n",
    "    percieved_text_rightfulness = 1-text_sentiment\n",
    "else:\n",
    "    percieved_text_rightfulness = text_sentiment\n",
    "\n",
    "print(f\"Percibimos que el texto es [{percieved_text_rightfulness}] correcto (0 es nada, 1 es completamente)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Calculamos nuestra reaccion al texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sobre nuestro interes [['cat']] nuestra opinion es asi de radical:\n",
      "0.8\n",
      "\n",
      "Nuestra reaccion es:\n",
      "Texto: \t\tCats are just the best! Garfield is getting lasagna tonight\n",
      "Polaridad:\t0.09999999999999998\n",
      "Intensidad:\t0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos una funcion para calcular la radicalidad de una polaridad\n",
    "calc_radicality = lambda p:abs(p-0.5)/0.5\n",
    "\n",
    "our_radicality = calc_radicality(our_polarity)\n",
    "\n",
    "# Calculamos la polaridad de nuestra reaccion\n",
    "react_polarity = our_radicality * percieved_text_rightfulness + 0.5 * (1-our_radicality)\n",
    "\n",
    "# Calculamos la fuerza de la reaccion\n",
    "react_strenght = 0.5*calc_radicality(react_polarity) + 0.5 * our_strenght \n",
    "\n",
    "print('''\n",
    "Sobre nuestro interes [{}] nuestra opinion es asi de radical:\n",
    "{}\n",
    "\n",
    "Nuestra reaccion es:\n",
    "Texto: \\t\\t{}\n",
    "Polaridad:\\t{}\n",
    "Intensidad:\\t{}\n",
    "'''.format(interest.get_keywords(), our_radicality, text, react_polarity, react_strenght))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
